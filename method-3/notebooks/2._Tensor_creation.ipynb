{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16af8098",
   "metadata": {},
   "source": [
    "# 2. Tensor creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac0513",
   "metadata": {},
   "source": [
    "2.1 Preparation <br>\n",
    "2.2 Whisper tensor creation <br>\n",
    "2.3 Tdnn tensor creation <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb54a74",
   "metadata": {},
   "source": [
    "## 2.1 Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc6f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which GPU to use\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # \"0\" -> usage of first GPU, \"1\" -> usage of second GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import os\n",
    "\n",
    "import whisper\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow  # required in Colab to avoid protobuf compatibility issues\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from speechbrain.pretrained import EncoderClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU and set device\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # Set Runtime to GPU in Google Colab\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "\n",
    "model = whisper.load_model(\"large\")\n",
    "language_id = EncoderClassifier.from_hparams(source=\"speechbrain/lang-id-voxlingua107-ecapa\", savedir=\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52632825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to get the embeddings\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957ef3a",
   "metadata": {},
   "source": [
    "## 2.2 Whisper tensor creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc21014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the files, create whisper embeddings and save them\n",
    "\n",
    "# Note: to create tensors for the different parts of the dataset, 'train', 'dev', and 'test' have to be specified in the \n",
    "# paths below\n",
    "\n",
    "dir = 'data/fleurs/downloads/extracted/'\n",
    "\n",
    "for i in range(0, 102):\n",
    "    \n",
    "    print(i+1)\n",
    "    current_dir = dir + os.listdir(dir)[i]\n",
    "    ln = os.listdir(current_dir)[0]\n",
    "    current_dir = current_dir + '/' + ln + '/audio/train/'\n",
    "    x = 0\n",
    "    new_dir = 'data/tensors_whisper/train/' + ln + '/'\n",
    "    \n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "\n",
    "    for f in tqdm(os.listdir(current_dir)):\n",
    "\n",
    "        file_path = current_dir + f\n",
    "\n",
    "        activation = {}\n",
    "        model.decoder.blocks[30].mlp_ln.register_forward_hook(get_activation('whisper'))\n",
    "\n",
    "        audio = whisper.load_audio(file_path)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "        # make log-Mel spectrogram and move to the same device as the model\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "        # detect the spoken language\n",
    "        _, probs = model.detect_language(mel)\n",
    "        ln_whisper = max(probs, key=probs.get)\n",
    "\n",
    "        #inp = torch.tensor(result.audio_features)\n",
    "        name = 'wtensor_' + ln + str(x) + '.pt'\n",
    "        save_path = 'data/tensors_whisper/train/' + ln + '/' + name\n",
    "\n",
    "        decoding_result = activation['whisper']\n",
    "        torch.save(decoding_result, save_path)\n",
    "\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad294b",
   "metadata": {},
   "source": [
    "## 2.3 Tdnn tensor creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624fe85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the files, create tdnn embeddings and save them\n",
    "\n",
    "# Note: to create tensors for the different parts of the dataset, 'train', 'dev', and 'test' have to be specified in the \n",
    "# paths below\n",
    "\n",
    "dir = 'data/fleurs/downloads/extracted/'\n",
    "\n",
    "for i in range(0, 102):\n",
    "    \n",
    "    print(i+1)\n",
    "    current_dir = dir + os.listdir(dir)[i]\n",
    "    ln = os.listdir(current_dir)[0]\n",
    "    current_dir = current_dir + '/' + ln + '/audio/train/'\n",
    "    x = 0\n",
    "    new_dir = 'data/tensors_tdnn/train/' + ln + '/'\n",
    "    \n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "\n",
    "    for f in tqdm(os.listdir(current_dir)):\n",
    "\n",
    "        file_path = current_dir + f\n",
    "\n",
    "        activation = {}\n",
    "        language_id.mods.classifier.DNN.block_0.norm.norm.register_forward_hook(get_activation('mods.classifier.DNN.block_0.norm.norm'))\n",
    "\n",
    "        signal = language_id.load_audio(file_path)\n",
    "        prediction =  language_id.classify_batch(signal)\n",
    "\n",
    "        #inp = torch.tensor(result.audio_features)\n",
    "        name = 'tensor_' + ln + str(x) + '.pt'\n",
    "        save_path = 'data/tensors_tdnn/train/' + ln + '/' + name\n",
    "\n",
    "        decoding_result = activation['mods.classifier.DNN.block_0.norm.norm']\n",
    "\n",
    "        torch.save(decoding_result, save_path)\n",
    "\n",
    "        x += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
